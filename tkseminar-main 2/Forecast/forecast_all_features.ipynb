{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TODO: This notebook will preprocess the data from the dataset containing all historic data of all risk factors to be in a format that Prophet can work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import logging\n",
    "from logging import log, INFO, ERROR, WARN, DEBUG\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class restcall():\n",
    "    steps = 0\n",
    "    training = False\n",
    "\n",
    "    def forecast(steps, df):\n",
    "        logging.basicConfig(level=INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "        logging.info(\"Number of chosen forecast steps: \" + str(steps))\n",
    "\n",
    "        # Parameters\n",
    "        algorithm = 'getProphetForecast'\n",
    "        url = 'http://localhost:8061/' + algorithm\n",
    "\n",
    "        logging.info(\"Read data ...\")\n",
    "        logging.info(\"POST request startet ...\")\n",
    "\n",
    "        # Prepare POST request\n",
    "        jsn = {\n",
    "            \"steps\": steps,\n",
    "            \"data\": df.to_json(orient='records')\n",
    "        }\n",
    "        response = json.dumps(jsn)\n",
    "        logging.info(\"Ready for POST ...\")\n",
    "\n",
    "        # Send POST and retrieve response\n",
    "        req = requests.post(url,response).content\n",
    "        logging.info(req)\n",
    "        output = pd.read_json(io.StringIO(req.decode('utf-8')))\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the Dataset\n",
    "df_historic = pd.read_csv(\"../DataAnalysis/Data/preprocessed_data.csv\")\n",
    "#df_historic = df_historic.drop('Unnamed: 0', axis=1)\n",
    "df_historic['Date'] = pd.to_datetime(df_historic.Date)\n",
    "df_historic['Date'] = df_historic['Date'].dt.strftime('%m/%d/%Y')\n",
    "# add indicator for historic and forecasted values\n",
    "df_historic['historic'] = 1\n",
    "df_historic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all columns and create tuples of date and feature\n",
    "for column in df_historic:\n",
    "    # Skip for Date and Index columns\n",
    "    if column == 'Date' or column == 'historic':\n",
    "        continue\n",
    "    # Prepare the tuple that is sent to the API\n",
    "    df_prophet = df_historic[['Date', column]]\n",
    "    # Retrieve forecasts\n",
    "    forecasts = restcall.forecast(365, df_prophet)\n",
    "    forecasts['DATE'] = pd.to_datetime(forecasts.DATE)\n",
    "    forecasts['DATE'] = forecasts['DATE'].dt.strftime('%m/%d/%Y')\n",
    "    forecasts = forecasts.rename(columns={'DATE':'Date'})\n",
    "    forecasts = forecasts.rename(columns={'Y': column})\n",
    "    \n",
    "    # If first iteration (column 'Price'), add forecast dates to our final dataset\n",
    "    if column == 'Price':\n",
    "        df_forecast = pd.DataFrame()\n",
    "        df_forecast['Date'] = forecasts['Date']\n",
    "    \n",
    "    # Inner join the forecasts on date\n",
    "    df_forecast = pd.merge(df_forecast, forecasts, on='Date')\n",
    "\n",
    "df_forecast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicate that these are forecasted values\n",
    "df_forecast['historic'] = 0\n",
    "df_forecast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df_historic, df_forecast], axis=0)\n",
    "df_final = df_final.reset_index(drop=True)\n",
    "df_final.tail(92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('./hist_forecast.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
